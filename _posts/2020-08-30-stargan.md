---
title: "[Review] (2017) StarGAN"
categories:
  - GAN
tags:
  - Deep Learning
  - GAN
  - Style Learning
comments: true
toc: true
toc_sticky: true
toc_label: Title
toc_color: green
---

# 1. Introduction

- 2개의 domain 간 image-to-image translation 연구가 많아지고 있음
- 하지만, scalability와 robustness가 부족함
- K개의 Multi-domain을 학습하려면 k(k-1)개의 generator를 학습해야함
- 그래서 StarGAN이라는 방법을 제안함
    - Fixed translation(black-to-blond hair)이 아닌 domain들의 이미지와 label정보를 이용하여 변환함
    - 학습하는 동안, 무작위로 target domain label을 생성하여 그 방향으로 생성하게 함
    - mask vector를 이용하여 unknow label을 무시하거나, 특정 label에 초점을 맞추도록 함
    - 하나의 generator, discriminator로 multi-domain 변환 학습이 가능함

# 2. Methods

![image](/assets/imgs/paper/2017-stargan/00.png)

### 2.1. Objective Functions

- 학습의 목표는 $G(x,c)\to y$
    - $G$ : Generator
    - $x$ : Input image
    - $c$ : Target domain label
    - $y$ : Output domain Image
- Discriminator쪽은 $D : x \to \{D_{src}(x),D_{cls}(x)\}$
- Adversarial Loss : Real, Fake 간 domain 차이를 모르게 하기 위해
    - $\mathcal{L}_{adv}=\mathbb{E}_{x}[\log D_{src}(x)]+\mathbb{E}_{x,c}[\log (1-D_{src}(G(x,c)))]$
- Domain Classification Loss
    - Domain 간 class 유추 능력을 동일하게 갖기 위해
    - For real : $\mathcal{L}_{cls}^r=\mathbb{E}_{x,c'}[-\log D_{cls}(c'|x)]$
    - For fake : $\mathcal{L}_{cls}^f=\mathbb{E}_{x,c'}[-\log D_{cls}(c|G(x,c))]$
    - $c'$ : Real image x와 일치하는 original domain
- Reconstruction Loss
    - adversarial loss와 domain classification loss는 generator가 만든 이미지가 realistic하다는 것은 보장하지만, domain translation이 잘된 것을 보장하지 않음
    - target domain으로 변화시켰다가 다시 original domain으로 변화시킨(reconstruction)것의 차이를 학습함
    - $\mathcal{L}_{rec}=\mathbb{E}_{x,c,c'}[ || x-G(G(x,c),c')  ||_{1} ]$
- Full Objective
    - $\mathcal{L}_D=\mathcal{L}_{adv}+\lambda_{cls}\mathcal{L}_{cls}^r$
    - $\mathcal{L}_G=\mathcal{L}_{adv}+\lambda_{cls}\mathcal{L}_{cls}^f+\lambda_{rec}\mathcal{L}_{rec}$
    - $\lambda_{cls}, \lambda_{rec}$ : hyperparameter

### 2.2. Training with Multiple Datasets

- StarGAN은 multi dataset의 multi labels을 엉켜서 잘 사용할 수 있는 것이 중요 이점임
- 하지만, multi dataset의 단점은 각 dataset간 부분적으로만 label이 같을 수 있다는 것임
- reconstruction loss 같은 것을 하기 어려움

### 2.3. Mask Vector

- $n$ 개의 dataset과 각 label을 $n$차원의 one-hot vector과 mask vector $m$으로 나타낼 때 dataset label을 다음과 같이 정의 함
- $\tilde{c}=[c_1,\cdots,c_n,m]$
- 만약, $c_i$가 i번째 dataset의 attribute을 의미하는 벡터라면(ex - facial expression), 이 알려진 vector에 대해서는 one-hot vector로 표현하고 남은 $n-1$개의 label은 모두 0으로 처리함

# 3. Experimental Results & Conclusion

![image](/assets/imgs/paper/2017-stargan/01.png)

### 3.1. Datasets

- CelebA : CelebFaces Attributes dataset. 202,599개의 이미지를 40개의 label로 나뉘어져 있음.
- RaFD : Radboud Faces Database는 67명의 참가자의 4,824개의 이미지로 구성됨. 8개의 표정들로 구성되며, 256x256의 크기를 갖음

### 3.2. Results

![image](/assets/imgs/paper/2017-stargan/02.png)

- AMT(Amazon Mechanical Turk)를 사용하여 평가 수행
- baseline으로 DIAT, CycleGAN, IcGAN을 사용
- single dataset보다 multi dataset사용 시 더 성능이 좋았음

![image](/assets/imgs/paper/2017-stargan/03.png)

- Mask vector를 제대로 적용안하면 위쪽 행과 다르게 아래쪽 행처럼 엉뚱한 결과가 나옴

- 간단한 아이디어로 성공적인 결과를 보임에 굉장히 놀라움
- G, D가 하나인데도 multi domain에 대한 이미지 생성이나 판단 능력이 떨어지지 않는다는 것은 (우리가 생각하기에)복잡한 문제를 풀기 위해 무리하게 모델이 클 필요는 없다는 반증 같음

# References

- [https://arxiv.org/abs/1711.09020](https://arxiv.org/abs/1711.09020)