---
title: "[Review] (2016) YOLO 9000"
categories:
  - Detection
tags:
  - DeepLearning
  - Detection
  - YOLO
comments: true
toc: true
toc_sticky: true
toc_label: Title
toc_color: green
---

# 1. Introduction

- 일반적인 목적의 Object detection은 많은 object를 인식할 수 있어야 함
- 하지만, Detection dataset은 labeling 과정이 classification보다 어려워 상대적으로 적은 수량(더 적은 카테고리, 더 적은 데이터양)이 있기 때문에 학습 효율이 떨어짐
    - 그래서 같이 사용하는 학습법을 개발함
- 기존 YOLO의 단점들을 보완하는 trick들을 사용하여 정확도 및 속도, 더 많은 object 수 인식 등의 향상을 이룸

# 2. Methods & Experimental Results

## 2.1. Better

- 기존 YOLO는 Fast R-CNN에 비해 localization error가 컸음
- Region proposal based method들에 비해 recall도 떨어짐
    - 기존 YOLO는 7x7의 작은 feature map과 Fully-connected layer로 직접 계산하는 좌표 측정 때문에 정확도가 낮음

### 2.1.1. Batch Normalization

- YOLO v2에서는 모든 Convolutional layer 다음에 batch norm을 넣어 학습 속도 향상과 정규화를  진행하도록 함

### 2.1.2. High Resolution Classifier

- 기존 VGG 16의 224x224로는 정확도가 떨어짐(작은 object를 인식하기 어려움)
- 그래서, 448x448로 증가 (Darknet-19를 backbone으로 바꿈)
- darknet은 googlenet 구조를 참고하여 만듦

### 2.1.3. Convolutional with Anchor Boxes

- YOLO는 FCN으로 직접 좌표를 계산하였는데, 이는 학습을 불안정하게 하고 효율적이지 못함
- 그래서 convolutional layer로 대체하고 마지막 feature map을 홀수 크기로 맞추기 위해 input도 416x416으로 변경함 (최종 scale down factor가 32이기 때문)
- Anchor box를 이용하여 모든 anchor box로부터 objectness와 class, IOU를 계산함

### 2.1.4. Dimension Clusters

![image](/assets/imgs/paper/2016-yolo-9000/00.png)

- Anchor box와 관련된 2가지 이슈 중 하나인 anchor box 종횡비 우선순위 문제를 해결하기 위함
- 기존 방법은 학습하기 좋은 종횡비를 손수 결정해야 했음
    - 어떻게 설정하느냐에 따라 학습효율이 달라짐

![image](/assets/imgs/paper/2016-yolo-9000/01.png)

- 이를 자동화하고 더 좋은 성능을 내기 위해 k-means로 학습 데이터셋에 대해 분석하여 대략적인 anchor box 종횡비를 우선순위화 함
    - 기존 metric인 euclidean distance로하면 더 error가 커지므로, 1-IOU의 계산법으로 새롭게 clustering
    - 가장 trade-off가 적은 것은 k=5로 하였을 때임
    - 기존 anchor box 및 다른 방법과 비교하니 성능이 좋았음

### 2.1.5. Direct location prediction

- Anchor box를 이용하면 학습이 불안정한 이슈가 있음(2번째 이슈)
    - 주요 원인은 box의 위치가 너무 random하게 예측됨
- 다른 방법(region proposal)에서는 다음과 같이 box 위치를 계산하여 제약이 덜함
    - $x=(t_x *w_a)-x_a$
    - $y=(t_y*h_a)-y_a$
    - $t_x, t_y$는 network의 predictions
- YOLO는 grid cell 내부에서만 좌표 값이 나오도록 제약되어 있고, activation function을 sigmoid를 사용하여 항상 0~1사이로 고정함
    - Anchor box를 그대로 사용하는 것보다 효율이 좋음
    
    ![image](/assets/imgs/paper/2016-yolo-9000/02.png)
    
    - 다음과 같은 5개의 prediction값들로 박스의 위치 및 크기를 결정함
    - $c_x, c_y$ : Grid cell의 좌상단 끝에서부터의 offset
    - $p_w,p_h$ : Anchor box의 우선 순위(prior)의 종횡비(width, height)
        - $b_x=\sigma(t_x)+c_x$
        - $b_y=\sigma(t_y)+c_y$
        - $b_w=p_we^{t_w}$
        - $b_h=p_he^{t_h}$
        - $Pr(object)*IOU(b,object)=\sigma(t_o)$

### 2.1.6. Fine-Grained Features

- Output feature map의 13x13은 small object를 인식하기에 적합하지 않음
- 그래서, 한 단계 위의 resolution인 26x26의 feature map을 concat하는 방법 사용
    - 26x26x512를 13x13x2048로 변형하여 concat

### 2.1.7. Multi-Scale Training

- 다양한 input image 크기에 대해 학습하기 위해 32배수의 이미지 크기를 랜덤하게 선택하여 10 batch 마다 학습하게 함
    - 최소 크기 320부터 최대 크기 608까지

## 2.2. Faster

### 2.2.1. Darknet-19

- 기존 backbone인 VGG-16은 성능도 준수하고 복잡하지 않아 여러모로 사용성이 좋지만 FLOPS가 커서 속도가 떨어짐
- Googlenet의 구조를 참고하여 Depthwise seperable convolution으로 FLOPS는 줄이되 성능은 VGG-16과 거의 유사한 custom model 개발
- 새롭게 만든 Darknet-19는 VGG-16과 같이 224x224에 맞춘 것이 아니라서 224x224 imagenet으로 pretraining 후, 448x448로 fine-tuning하여 사용함

## 2.3. Stronger

- Object detection dataset은 label이 common함 (dog, cat, etc..)
- Classification dataset은 더 deeper, detail (dog - Norfolk terrier, Yorkshire terrier, etc...)
    - Classification의 output은 softmax 형태임
    - 이는 서로 label들이 mutual exclusive하다는 것을 전제로 함
- 더 다양한 object recognition을 위해 detection dataset과 classification dataset을 합치려면 관계의 정의를 달리 해야함

### 2.3.1. Hierarchical classification

![image](/assets/imgs/paper/2016-yolo-9000/03.png)

- ImageNet 데이터는 WordNet기반의 데이터임
    - WordNet은 word 간 관련성으로 묶어놓았는데 tree구조가 아닌 graphed graph구조임
    - 필요한 건 tree구조이기 때문에 tree구조 형태로 변형함
- 메인 단어 →관련어(sysnet)→관련어2(sysnet) 등으로 계층적 구조를 만듦
    - tree의 깊이는 최대한 얇게하고, 루트에서 특정 노드까지가 경로가 많으면 가장 짧은 것을 선택
    - 어떤 label에 대한 확률은 조건부 확률로 계산함
    - 구성된 WordTree dataset의 결과는 multi-softmax를 사용함.
        - 공통된 카테고리의 단어들에 대한 softmax 후, 그 안에서 세부적인 label에 대한 softmax를 수행

### 2.3.2. Joint classification and detection

![image](/assets/imgs/paper/2016-yolo-9000/04.png)

- COCO + ImageNet dataset은 9,000개가 넘는 카테고리를 갖음
    - COCO가 ImageNet에 비해 많이 적으므로 oversampling을 4배하여 학습함
- output size가 너무 부담되어 prior를 5개에서 3개로 줄임
- 학습을 위한 backpropagation은 두 가지로 나눔
    - Detection용 이미지가 들어올 때는 정상적으로 진행
        - classification loss는 해당 클래스와 그것의 상위 클래스에 대해서만 loss를 전파함
        - 만약 label이 '개'면 그 아래의 모든 label에 전파함
    - Classification용 이미지가 들어오면, classification loss만 전파함
- 실제 성능을 테스트해보니 동물류는 COCO dataset에서 세부분류가 되어있어 잘 찾지만, 의류 등의 데이터는 잘 안되었음

# 3. Conclusion

- YOLO v2는 input image size를 조절하여 정확도와 속도를 trade-off 가능함
    - 애초에 학습부터 multi-scale input으로하여 한 번에 학습으로도 다양한 input 크기에 대해 적용 가능
- YOLO 9000은 v2에 대해 COCO+ImageNet이라는 커다란 데이터셋을 학습한 것으로 detection dataset의 약점을 보완하는 방법을 제안함
    - 이런 방법은 detection 뿐 아니라 다른 곳에서도 유용하게 사용될 수 있음